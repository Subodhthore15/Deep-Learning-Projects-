{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST with ANN (hello world).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2828b44c2414245935dc7533f023093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e193ecc908b5410499759b544012138e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_433c78dbbe5942eeadd42a013738b960",
              "IPY_MODEL_4769906682ef453f816fe8a3e6d28900"
            ]
          }
        },
        "e193ecc908b5410499759b544012138e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "433c78dbbe5942eeadd42a013738b960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1f9b6eeacc5a4eb4a39645f989ce3716",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a559ac8bc86a428aaa1c408bae1dc278"
          }
        },
        "4769906682ef453f816fe8a3e6d28900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f3cd890528146438a0ec87f2bf6b16d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:05&lt;00:00,  1.48s/ file]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3a76e4c54634ede9ad18858488a552b"
          }
        },
        "1f9b6eeacc5a4eb4a39645f989ce3716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a559ac8bc86a428aaa1c408bae1dc278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f3cd890528146438a0ec87f2bf6b16d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3a76e4c54634ede9ad18858488a552b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmQGGXMhekyr"
      },
      "source": [
        "\r\n",
        "The dataset is called MNIST and refers to handwritten digit recognition. You can find more about it on Yann LeCun's website (Director of AI Research, Facebook). He is one of the pioneers of what we've been talking about and of more complex approaches that are widely used today, such as covolutional neural networks (CNNs). \r\n",
        "\r\n",
        "The dataset provides 70,000 images (28x28 pixels) of handwritten digits (1 digit per image). \r\n",
        "\r\n",
        "The goal is to write an algorithm that detects which digit is written. Since there are only 10 digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), this is a classification problem with 10 classes. \r\n",
        "\r\n",
        "# This problem is called \"Hello World\" of deep learning because for most students it is the first deep learning algorithm they see."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIqh1uP3gDxk"
      },
      "source": [
        "## Import the relevant packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "d_K-5qN8MhL9",
        "outputId": "6e0cf6aa-7655-4246-ee3c-7e88f2d7777c"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BF4ZHeUgSYZ"
      },
      "source": [
        "## Data|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "a2828b44c2414245935dc7533f023093",
            "e193ecc908b5410499759b544012138e",
            "433c78dbbe5942eeadd42a013738b960",
            "4769906682ef453f816fe8a3e6d28900",
            "1f9b6eeacc5a4eb4a39645f989ce3716",
            "a559ac8bc86a428aaa1c408bae1dc278",
            "3f3cd890528146438a0ec87f2bf6b16d",
            "b3a76e4c54634ede9ad18858488a552b"
          ]
        },
        "id": "cOYVwk1WehqI",
        "outputId": "409c1b4e-9425-41ee-f93f-b0a4dce8e53a"
      },
      "source": [
        "dataset , info =tfds.load(name='mnist',as_supervised=True, with_info=True) \r\n",
        "\r\n",
        "# as_supervised  =True will  load the dataset in a 2-tuple structure (input, target) \r\n",
        "\r\n",
        "# as_supervised=False, would return a dictionary\r\n",
        "# obviously we prefer to have our inputs and targets separated \r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
            "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2828b44c2414245935dc7533f023093",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW4vN3aAgyxT",
        "outputId": "06e90398-b444-4053-bb51-10272ea674c3"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': <PrefetchDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>,\n",
              " 'train': <PrefetchDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fgc_d6BhKHL",
        "outputId": "0ff549ab-5301-4a04-8a53-fd085467c2ec"
      },
      "source": [
        "dataset['train']\r\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zlOkQQAhSAw"
      },
      "source": [
        "mnist_train , mnist_test = dataset['train'] , dataset['test'] \r\n",
        "\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QeqpnH4iyzz",
        "outputId": "c6d0bf9f-c1fd-4458-eae5-e6cc5b246519"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi45w2-Xh5u8",
        "outputId": "8e19a2d3-1c39-4daf-f24c-7ec05ab3122d"
      },
      "source": [
        "info.splits['train'].num_examples  # you get number of training samples "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3puTm43hq5q"
      },
      "source": [
        "# create validation data manually(method - 1)\r\n",
        "\r\n",
        "num_validation_samples = 0.1 * info.splits['train'].num_examples\r\n",
        "\r\n",
        "num_validation_samples = tf.cast(num_validation_samples,tf.int64)  # convert variable into given datatype\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "num_test_samples = info.splits['test'].num_examples\r\n",
        "\r\n",
        "num_test_samples = tf.cast(num_validation_samples,tf.int64)\r\n",
        "\r\n",
        "\r\n",
        "def scale(image, label):\r\n",
        "    # we make sure the value is a float\r\n",
        "    image = tf.cast(image, tf.float32)\r\n",
        "    # since the possible values for the inputs are 0 to 255 (256 different shades of grey)\r\n",
        "    # if we divide each element by 255, we would get the desired result -> all elements will be between 0 and 1 \r\n",
        "    image /= 255.\r\n",
        "\r\n",
        "    return image, label\r\n",
        "\r\n",
        "\r\n",
        "# the method .map() allows us to apply a custom transformation to a given dataset\r\n",
        "# we have already decided that we will get the validation data from mnist_train, so \r\n",
        "scaled_train_and_validation_data = mnist_train.map(scale)\r\n",
        "\r\n",
        "\r\n",
        "test_data = mnist_test.map(scale)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zdiIEu9kS9y"
      },
      "source": [
        "# shuffling the data \r\n",
        "\r\n",
        "BUFFER_SIZE = 10000\r\n",
        "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# seprate train and validation data by take() and skip() methods\r\n",
        "\r\n",
        "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\r\n",
        "\r\n",
        "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\r\n",
        "\r\n",
        "# we create multiple batchwes only for train data \r\n",
        "BATCH_SIZE = 100\r\n",
        "\r\n",
        "# we can also take advantage of the occasion to batch the train data\r\n",
        "# this would be very helpful when we train, as we would be able to iterate over the different batches\r\n",
        "train_data = train_data.batch(BATCH_SIZE)\r\n",
        "\r\n",
        "\r\n",
        "# it doesn't need but we prefer to do it only one batch \r\n",
        "validation_data = validation_data.batch(num_validation_samples)\r\n",
        "\r\n",
        "# batch the test data\r\n",
        "test_data = test_data.batch(num_test_samples)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# takes next batch (it is the only batch)\r\n",
        "# because as_supervized=True, we've got a 2-tuple structure\r\n",
        "validation_inputs, validation_targets = next(iter(validation_data)) # take next validatiion "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT9peHLUqYL6"
      },
      "source": [
        "#Building the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUb2iAQCoul2"
      },
      "source": [
        "input_size = 784\r\n",
        "output_size = 10\r\n",
        "\r\n",
        "hidden_layer_size = 50\r\n",
        "    \r\n",
        "\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "    \r\n",
        "   \r\n",
        "    # there is a convenient method 'Flatten' that simply takes our 28x28x1 tensor and orders it into a (None,) \r\n",
        "    # or (28x28x1,) = (784,) vector\r\n",
        "    \r\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # input layer\r\n",
        "    \r\n",
        "    # tf.keras.layers.Dense is basically implementing: output = activation(dot(input, weight) + bias)\r\n",
        "    # it takes several arguments, but the most important ones for us are the hidden_layer_size and the activation function\r\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\r\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\r\n",
        "\r\n",
        "#  we just make sure to activate it with softmax\r\n",
        "    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\r\n",
        "])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeNJJn3_quxI"
      },
      "source": [
        "# Choose the optimizer  ,  loss function and loss fun  \r\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maZCwjsurKLk",
        "outputId": "16e7c7ba-66ae-4662-9fb7-dd82328991e0"
      },
      "source": [
        "# determine the maximum number of epochs\r\n",
        "NUM_EPOCHS = 5\r\n",
        "\r\n",
        "# and the validation data we just created ourselves in the format: (inputs,targets)\r\n",
        "r=model.fit(train_data, epochs=NUM_EPOCHS, validation_data=(validation_inputs, validation_targets), verbose =2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "540/540 - 6s - loss: 0.4236 - accuracy: 0.8796 - val_loss: 0.2274 - val_accuracy: 0.9333\n",
            "Epoch 2/5\n",
            "540/540 - 3s - loss: 0.1837 - accuracy: 0.9468 - val_loss: 0.1559 - val_accuracy: 0.9552\n",
            "Epoch 3/5\n",
            "540/540 - 3s - loss: 0.1383 - accuracy: 0.9591 - val_loss: 0.1260 - val_accuracy: 0.9632\n",
            "Epoch 4/5\n",
            "540/540 - 3s - loss: 0.1121 - accuracy: 0.9665 - val_loss: 0.1105 - val_accuracy: 0.9685\n",
            "Epoch 5/5\n",
            "540/540 - 3s - loss: 0.0932 - accuracy: 0.9722 - val_loss: 0.0930 - val_accuracy: 0.9705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7rP4VWcsDDd",
        "outputId": "e30315de-02fb-40c9-b320-e7fe0974c8bf"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 1s 287ms/step - loss: 0.0967 - accuracy: 0.9699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEUVgSEeuDF9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}